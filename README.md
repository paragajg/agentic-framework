# Agentic Framework

> **Enterprise-grade multi-agent orchestration platform for building production-ready LLM workflows**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![GitHub Release](https://img.shields.io/github/v/release/paragajg/agentic-framework)](https://github.com/paragajg/agentic-framework/releases)

## ğŸ“‹ Table of Contents

- [What is Agentic Framework?](#-what-is-agentic-framework)
- [Why Agentic Framework?](#-why-agentic-framework)
- [Architecture](#-architecture)
- [Key Concepts](#-key-concepts)
- [Features](#-features)
- [Quick Start](#-quick-start)
- [CLI Usage Guide](#-cli-usage-guide)
- [Multi-Agent Patterns](#-multi-agent-patterns)
- [LLM Provider Support](#-llm-provider-support)
- [Examples](#-examples)
- [Development](#-development)
- [Production Deployment](#-production-deployment)
- [Contributing](#-contributing)
- [FAQ](#-faq)

## ğŸ¯ What is Agentic Framework?

**Agentic Framework** is an open-source, production-ready platform for building complex multi-agent systems powered by Large Language Models. It enables developers to orchestrate multiple specialized AI agents that collaborate to solve complex tasks through a **declarative YAML-based workflow system**.

### Who is this for?

- **Enterprise developers** building scalable AI applications
- **AI engineers** creating multi-step reasoning systems
- **Research teams** experimenting with agent architectures
- **Product teams** integrating LLMs into production workflows

### What problems does it solve?

âœ… **No vendor lock-in** - Switch between 6 LLM providers (Anthropic, OpenAI, Azure, Gemini, Ollama, vLLM)
âœ… **Safe tool execution** - Sandboxed Python skills + MCP gateway for external tools
âœ… **Memory management** - Multi-tier storage with automatic compaction
âœ… **Auditability** - Full provenance tracking for compliance
âœ… **Scalability** - Production-grade architecture with observability
âœ… **Governance** - RBAC, approval workflows, and policy enforcement

## ğŸ¤” Why Agentic Framework?

| Feature | Agentic Framework | LangChain | AutoGen | Other Frameworks |
|---------|-------------------|-----------|---------|------------------|
| **LLM Agnostic** | âœ… 6 providers | âš ï¸ Limited | âš ï¸ OpenAI-focused | âŒ Vendor-locked |
| **Declarative Workflows** | âœ… YAML manifests | âŒ Code-only | âŒ Code-only | âš ï¸ Limited |
| **Typed Artifacts** | âœ… JSON Schema | âŒ No validation | âŒ No validation | âš ï¸ Basic |
| **Provenance Tracking** | âœ… Full audit trail | âŒ No | âŒ No | âŒ No |
| **Sandboxed Execution** | âœ… Isolated skills | âš ï¸ Unsafe | âš ï¸ Unsafe | âŒ No |
| **MCP Integration** | âœ… Native support | âŒ No | âŒ No | âŒ No |
| **Enterprise Features** | âœ… RBAC, approvals | âŒ No | âŒ No | âš ï¸ Limited |
| **Memory Management** | âœ… Multi-tier (4 layers) | âš ï¸ Basic | âš ï¸ Basic | âŒ No |

## ğŸ—ï¸ Architecture

### High-Level System Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              USER / CLIENT                                   â”‚
â”‚                    (CLI, API, Web Interface, SDK)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        LEAD AGENT / ORCHESTRATOR                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  â€¢ Workflow Planning & Decomposition                                 â”‚   â”‚
â”‚  â”‚  â€¢ YAML Manifest Parser                                              â”‚   â”‚
â”‚  â”‚  â€¢ Subagent Task Assignment                                          â”‚   â”‚
â”‚  â”‚  â€¢ Artifact Validation & Routing                                     â”‚   â”‚
â”‚  â”‚  â€¢ Human-in-the-Loop Approval Gates                                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â–¼               â–¼               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   SUBAGENT     â”‚  â”‚   SUBAGENT     â”‚  â”‚   SUBAGENT     â”‚
    â”‚   MANAGER      â”‚  â”‚   MANAGER      â”‚  â”‚   MANAGER      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                   â”‚                   â”‚
            â”‚                   â”‚                   â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                â”‚  â”‚                â”‚  â”‚                â”‚
    â–¼                â–¼  â–¼                â–¼  â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Researchâ”‚  â”‚Verify  â”‚  â”‚  Code  â”‚  â”‚Analysisâ”‚  â”‚Synthesisâ”‚ â”‚Custom  â”‚
â”‚ Agent  â”‚  â”‚ Agent  â”‚  â”‚ Agent  â”‚  â”‚ Agent  â”‚  â”‚ Agent  â”‚  â”‚ Agent  â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
    â”‚           â”‚           â”‚           â”‚           â”‚           â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”    â”‚
    â”‚  â”‚         TYPED ARTIFACTS (JSON Schema)              â”‚    â”‚
    â”‚  â”‚  â€¢ research_snippet  â€¢ claim_verification          â”‚    â”‚
    â”‚  â”‚  â€¢ code_patch        â€¢ synthesis_result            â”‚    â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
    â”‚                                                             â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                    â”‚                    â”‚
         â–¼                    â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CODE EXECUTOR   â”‚  â”‚   MCP GATEWAY    â”‚  â”‚ MEMORY SERVICE   â”‚
â”‚  (Skills)        â”‚  â”‚   (Tools)        â”‚  â”‚ (4-Tier Storage) â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Skill Registry â”‚  â”‚ â€¢ Tool Catalog   â”‚  â”‚ â€¢ Session (Redis)â”‚
â”‚ â€¢ JIT Loading    â”‚  â”‚ â€¢ Discovery      â”‚  â”‚ â€¢ Vector (Milvus)â”‚
â”‚ â€¢ Sandboxed Exec â”‚  â”‚ â€¢ Auth & Scopes  â”‚  â”‚ â€¢ Struct (Postgres)â”‚
â”‚ â€¢ Safety Flags   â”‚  â”‚ â€¢ Rate Limiting  â”‚  â”‚ â€¢ Cold (S3/MinIO)â”‚
â”‚ â€¢ Dual Format:   â”‚  â”‚ â€¢ PII Filtering  â”‚  â”‚ â€¢ Auto-Compactionâ”‚
â”‚   - Native       â”‚  â”‚ â€¢ Proxy Runtime  â”‚  â”‚ â€¢ Provenance Log â”‚
â”‚   - Anthropic    â”‚  â”‚                  â”‚  â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                    â”‚                    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  EXTERNAL WORLD   â”‚
                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                    â”‚ â€¢ File System     â”‚
                    â”‚ â€¢ Databases       â”‚
                    â”‚ â€¢ Web APIs        â”‚
                    â”‚ â€¢ GitHub/Jira     â”‚
                    â”‚ â€¢ Slack/Email     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        CROSS-CUTTING CONCERNS                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ Observability: OpenTelemetry (Metrics, Traces, Logs)                     â”‚
â”‚  â€¢ Security: RBAC, Audit Trails, Policy Enforcement (OPA)                   â”‚
â”‚  â€¢ Governance: Approval Workflows, Budget Limits, Guardrails                â”‚
â”‚  â€¢ Monitoring: Prometheus, Grafana Dashboards                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow: How a Workflow Executes

```
1. USER submits task
   â†“
2. ORCHESTRATOR parses YAML manifest
   â†“
3. ORCHESTRATOR spawns SUBAGENT (e.g., Research Agent)
   â”œâ”€ Binds skills: [web_search, summarize]
   â”œâ”€ Binds MCP tools: [github.*, firecrawl.*]
   â””â”€ Sets context: isolated LLM session
   â†“
4. SUBAGENT executes task
   â”œâ”€ Calls CODE EXECUTOR for deterministic skills
   â”œâ”€ Calls MCP GATEWAY for external tools
   â”œâ”€ Reads/writes MEMORY SERVICE
   â””â”€ Produces TYPED ARTIFACT (validated by JSON Schema)
   â†“
5. ORCHESTRATOR validates artifact
   â”œâ”€ Schema validation (structure)
   â”œâ”€ Safety checks (PII, harmful content)
   â””â”€ Provenance logging (who, what, when, why)
   â†“
6. ORCHESTRATOR passes artifact to next SUBAGENT
   â†“
7. Repeat steps 3-6 for each workflow step
   â†“
8. ORCHESTRATOR returns FINAL ARTIFACT to user
   â”œâ”€ Stores in MEMORY SERVICE
   â””â”€ Logs provenance chain
```

## ğŸ§© Key Concepts

### 1. **Typed Artifacts**
Structured, validated data passed between agents:
```python
research_snippet = {
    "id": "uuid",
    "source": {"url": "...", "doc_id": "..."},
    "text": "...",
    "summary": "...",
    "tags": ["ai", "agents"],
    "confidence": 0.95,
    "provenance": {...},  # Full audit trail
    "created_by": "research-agent-01",
    "created_at": "2024-01-01T10:00:00Z"
}
```

### 2. **Skills (Deterministic Functions)**
Sandboxed Python code executed by Code Executor:
- **Native Format**: `skill.yaml` + `schema.json` + `handler.py`
- **Anthropic Format**: `SKILL.md` (marketplace compatible)
- **Hybrid Format**: Both (recommended for sharing)
- **Safety Flags**: `pii_risk`, `file_system`, `network_access`, `side_effect`
- **JIT Loading**: Skills loaded on-demand, cached for performance

### 3. **MCP Tools (External Services)**
Model Context Protocol integration for safe external access:
- **Tool Catalog**: Pre-approved tools (filesystem, github, postgres, slack)
- **Scoped Access**: Fine-grained permissions (e.g., `repo:read`, `issues:write`)
- **Rate Limiting**: Configurable per tool/server
- **PII Filtering**: Automatic scrubbing of sensitive data

### 4. **Capabilities**
What an agent can do:
```yaml
capabilities:
  - web_search      # MCP tool
  - summarize       # Native skill
  - code_execution  # Native skill
  - kb_search       # MCP tool
```

### 5. **Provenance**
Full audit trail for every artifact:
```json
{
  "actor_id": "research-agent-01",
  "actor_type": "subagent",
  "inputs_hash": "sha256:...",
  "outputs_hash": "sha256:...",
  "tool_ids": ["web_search", "summarize"],
  "timestamp": "2024-01-01T10:00:00Z",
  "parent_artifact_id": "uuid"
}
```

### 6. **Memory Tiers**
4-layer storage hierarchy:
- **Session (Redis)**: Hot, fast access for active workflows
- **Vector (Milvus/Chroma)**: Semantic search for retrieval
- **Structured (Postgres)**: Queryable metadata and provenance
- **Cold (S3/MinIO)**: Long-term archival storage

## âœ¨ Features

### Core Platform
- ğŸ”„ **LLM-Agnostic Architecture**: Swap providers without code changes
- ğŸ“ **YAML-Based Workflows**: Declarative, version-controlled manifests
- ğŸ› ï¸ **Dual-Format Skills**: Native + Anthropic marketplace compatible
- ğŸ”Œ **MCP Integration**: 50+ pre-built tool servers
- ğŸ“Š **Full Observability**: OpenTelemetry metrics, traces, logs
- ğŸ” **Enterprise Security**: RBAC, audit trails, policy enforcement
- ğŸ¯ **Typed Artifacts**: JSON Schema validated inter-agent communication

### Developer Experience
- ğŸš€ **agentctl CLI**: Interactive agent/workflow management
- ğŸ“š **Rich Examples**: 4+ complete working examples
- ğŸ§ª **Comprehensive Tests**: 90%+ code coverage
- ğŸ“– **Extensive Docs**: Architecture, API, guides
- ğŸ³ **Docker Support**: Full-stack compose files
- â˜¸ï¸ **Kubernetes Ready**: Helm charts for production

### Production Features
- âš¡ **Performance**: JIT skill loading, connection pooling, caching
- ğŸ“ˆ **Scalability**: Horizontal scaling, async execution
- ğŸ”„ **Reliability**: Retries, timeouts, circuit breakers
- ğŸ›¡ï¸ **Safety**: Sandboxed execution, PII filtering, guardrails
- ğŸ‘¥ **Collaboration**: Human-in-the-loop approvals
- ğŸ“Š **Monitoring**: Prometheus metrics, Grafana dashboards

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.11+** ([Download](https://www.python.org/downloads/))
- **Docker & Docker Compose** (for infrastructure services)
- **LLM API Key** (Anthropic, OpenAI, Azure, or Gemini)

### Step 1: Installation

**Option A: Install from GitHub (Recommended)**
```bash
# Install latest release
pip install git+https://github.com/paragajg/agentic-framework.git@v1.0.0

# Or install from main branch
pip install git+https://github.com/paragajg/agentic-framework.git
```

**Option B: Install from Source (for development)**
```bash
# Clone repository
git clone https://github.com/paragajg/agentic-framework.git
cd agentic-framework

# Create virtual environment
python3.11 -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install in editable mode
pip install -e .
```

### Step 2: Set Up LLM Provider

```bash
# Choose one provider:

# Anthropic (Recommended)
export ANTHROPIC_API_KEY="sk-ant-..."

# OpenAI
export OPENAI_API_KEY="sk-..."

# Azure OpenAI
export AZURE_OPENAI_KEY="..."
export AZURE_OPENAI_ENDPOINT="https://your-resource.openai.azure.com/"

# Google Gemini
export GEMINI_API_KEY="..."

# Local (Ollama - no API key needed)
# 1. Install: https://ollama.ai
# 2. Start: ollama serve
# 3. Pull model: ollama pull llama3.1:70b
```

### Step 3: Start Infrastructure (Optional)

```bash
# Start Redis, Postgres, Milvus for production features
docker-compose up -d
```

### Step 4: Verify Installation

```bash
# Check CLI is installed
agentctl --version
# Output: agentctl version 1.0.0

# Test LLM connection
agentctl llm test
# Output: âœ“ Connected to Anthropic Claude Sonnet 4
```

### Step 5: Run Your First Agent

```bash
# Navigate to example
cd examples/01-simple-agent

# Run the agent
python run.py
```

**Expected Output:**
```
==========================================================
Simple Agent Example
==========================================================

ğŸ“ Task: Research the latest trends in AI agents

ğŸ¤– Agent Configuration:
   - Role: Research
   - Capabilities: web_search, summarize
   - LLM: Anthropic Claude

ğŸ”„ Execution Flow:
   [1/3] Spawning research agent...
   [2/3] Executing research task...
   [3/3] Processing results...

âœ… Results:
    Research Summary:
    - AI agents are increasingly using multi-agent architectures
    - LLM orchestration frameworks are gaining adoption
    - Key trends: tool use, planning, memory systems
    - Enterprise focus: governance, observability, safety

    Sources: 3 web pages analyzed
    Confidence: 0.85
```

### Step 6: Create Your First Workflow

```bash
# Create a new workflow
agentctl manifest new

# Follow the interactive prompts:
# ? Manifest name: my-workflow
# ? Description: My first agent workflow
# ? Add step: research
#   ? Role: research
#   ? Capabilities: web_search, summarize
# ? Add step: synthesize
#   ? Role: synthesis
#   ? Capabilities: none
```

This generates `manifests/my-workflow.yaml`:

```yaml
manifest_id: my-workflow
name: My First Agent Workflow
version: "1.0.0"

steps:
  - id: research
    role: research
    capabilities: [web_search, summarize]
    inputs:
      - name: query
        source: user_input
    outputs: [research_snippet]
    timeout: 30

  - id: synthesize
    role: synthesis
    inputs:
      - name: research
        source: previous_step
    outputs: [final_report]
    timeout: 20
```

**Run the workflow:**
```bash
agentctl manifest run manifests/my-workflow.yaml \
  --input "Analyze the impact of multi-agent systems on enterprise AI"
```

## ğŸ® CLI Usage Guide

The `agentctl` CLI is the primary interface for building and managing agents. It provides an interactive, guided experience for:

- **Agent Creation**: Build agents without writing code
- **Workflow Design**: Create multi-step workflows interactively
- **LLM Configuration**: Switch between 6 providers seamlessly
- **Skill Development**: Scaffold skills with validation
- **MCP Integration**: Add external tools with guided setup
- **Deep Research**: Use as a research platform with multi-agent orchestration

### Quick CLI Examples

**Interactive Mode:**
```bash
# Launch interactive CLI
agentctl

# You'll see:
> _

# Try these commands:
> /agent new my-agent          # Create an agent
> /skill new my-skill          # Create a skill
> /manifest new                # Create a workflow
> /llm config                  # Configure LLM
> /mcp add github              # Add MCP server
> /research --mode interactive # Start research session
```

**Direct Commands:**
```bash
# Create agent in one line
agentctl agent new research-agent --role research --capabilities web_search,summarize

# Run workflow
agentctl manifest run manifests/my-workflow.yaml --input "Your query here"

# Test LLM connection
agentctl llm test

# List available skills
agentctl skill list
```

### Interactive Research Platform

Use `agentctl` as a deep research platform:

```bash
> /research --mode interactive

research> /query "Latest trends in multi-agent AI systems"

# Multi-phase research:
# 1. Initial search (web, academic, code repos)
# 2. Confidence-based deep dive
# 3. Fact verification
# 4. Progressive report building

research> /refine "game-theoretic approaches"
research> /verify
research> /sources
research> /export markdown
```

### Complete Guide

ğŸ“– **[Read the full CLI Usage Guide](docs/cli-usage.md)** for:
- 10 complete interactive sessions (beginner â†’ advanced)
- Deep research platform tutorial (42-minute example)
- Parallel workflow orchestration
- Complete command reference (40+ commands)
- Tips, tricks, and troubleshooting

## ğŸ­ Multi-Agent Patterns

The framework supports multiple orchestration patterns:

### 1. **Pipeline (Sequential)**
Agents execute in a linear sequence:
```
User â†’ Research Agent â†’ Verification Agent â†’ Synthesis Agent â†’ Output
```
**Use cases**: Research reports, data analysis, content generation

### 2. **Hierarchical Delegation**
Lead agent delegates subtasks to specialized agents:
```
         Lead Agent
        /     |     \
   Research  Code  Analysis
```
**Use cases**: Complex problem decomposition, project planning

### 3. **Fan-Out/Fan-In (Parallel)**
Multiple agents work in parallel, results merged:
```
        Lead Agent
       /    |    \
   Agent1 Agent2 Agent3
       \    |    /
      Aggregator Agent
```
**Use cases**: Distributed search, parallel validation, consensus building

### 4. **Supervisor Pattern**
Supervisor monitors and validates agent outputs:
```
Worker Agent â†’ Supervisor Agent â†’ (retry or approve)
```
**Use cases**: Quality control, compliance checking, safety validation

### 5. **Specialist Team**
Domain-specific agents collaborate:
```
Product Manager Agent â†” Engineering Agent â†” QA Agent
```
**Use cases**: Software development, cross-functional workflows

## ğŸŒ LLM Provider Support

### Supported Providers (6)

| Provider | Type | Models | Best For | Cost |
|----------|------|--------|----------|------|
| **Anthropic** | Cloud | Claude Opus 4.5, Sonnet 4.5, Haiku 4 | Enterprise, reasoning | $3-15/M tokens |
| **OpenAI** | Cloud | GPT-4o, GPT-4o-mini | General purpose | $2.50-15/M tokens |
| **Azure OpenAI** | Cloud | GPT-4o, GPT-4 Turbo | Enterprise Azure | $2.50-15/M tokens |
| **Google Gemini** | Cloud | Gemini 2.0 Flash, 1.5 Pro | Multimodal, cost-effective | $0.075-7/M tokens |
| **Ollama** | Local | Llama 3.1, Mistral, Mixtral | Privacy, offline | $0 (self-hosted) |
| **vLLM** | Local | Any HuggingFace model | High performance | $0 (self-hosted) |

### Quick Provider Switch

```bash
# Configure provider
agentctl llm config --provider anthropic --model claude-sonnet-4-20250514

# Or switch at runtime
agentctl manifest run workflow.yaml --llm-provider openai --llm-model gpt-4o
```

## ğŸ¯ Examples

Explore [examples/](examples/) for complete working projects:

| Example | Description | What You'll Learn | Difficulty |
|---------|-------------|-------------------|------------|
| [01-simple-agent](examples/01-simple-agent/) | Single research agent | Basic agent creation, skill binding | â­ Beginner |
| 02-multi-step-workflow | Sequential pipeline | Workflow orchestration, artifact passing | â­â­ Intermediate |
| 03-custom-skill | Build your own skill | Skill development, schema validation | â­â­ Intermediate |
| 04-mcp-integration | External tool access | MCP gateway, scoped permissions | â­â­â­ Advanced |

### Running Examples

```bash
# Navigate to example directory
cd examples/01-simple-agent

# Install any additional dependencies
pip install -r requirements.txt  # if present

# Run the example
python run.py
```

## ğŸ”§ Development

### Setup Development Environment

```bash
# Clone repository
git clone https://github.com/paragajg/agentic-framework.git
cd agentic-framework

# Create virtual environment
python3.11 -m venv .venv
source .venv/bin/activate

# Install with development dependencies
pip install -e ".[dev]"

# Start infrastructure services
docker-compose up -d

# Verify setup
pytest  # Run tests
```

### Code Quality Standards

```bash
# Format code
black --line-length 100 .

# Type checking
mypy --strict .

# Linting
ruff check .

# Run all checks
make lint  # or manually run all above
```

### Running Tests

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=. --cov-report=html

# Run specific test file
pytest tests/test_orchestrator.py

# Run specific test
pytest tests/test_orchestrator.py::test_workflow_execution -v
```

### Project Structure

```
agentic-framework/
â”œâ”€â”€ adapters/              # LLM provider adapters (6 providers)
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ anthropic.py   # Anthropic Claude
â”‚   â”‚   â”œâ”€â”€ openai.py      # OpenAI GPT
â”‚   â”‚   â”œâ”€â”€ azure.py       # Azure OpenAI
â”‚   â”‚   â”œâ”€â”€ gemini.py      # Google Gemini
â”‚   â”‚   â”œâ”€â”€ local.py       # Ollama (local)
â”‚   â”‚   â””â”€â”€ vllm.py        # vLLM (optimized local)
â”‚   â””â”€â”€ tests/
â”‚
â”œâ”€â”€ orchestrator/          # Workflow orchestration engine
â”‚   â”œâ”€â”€ service/
â”‚   â”‚   â”œâ”€â”€ workflow_engine.py  # YAML manifest execution
â”‚   â”‚   â”œâ”€â”€ approvals.py        # Human-in-the-loop
â”‚   â”‚   â””â”€â”€ models.py
â”‚   â”œâ”€â”€ manifests/         # Example workflow YAMLs
â”‚   â””â”€â”€ tests/
â”‚
â”œâ”€â”€ subagent-manager/      # Subagent lifecycle management
â”‚   â”œâ”€â”€ service/
â”‚   â”‚   â”œâ”€â”€ lifecycle.py        # Spawn, execute, destroy
â”‚   â”‚   â”œâ”€â”€ governance.py       # RBAC, policies
â”‚   â”‚   â”œâ”€â”€ validator.py        # Artifact validation
â”‚   â”‚   â””â”€â”€ provenance.py       # Audit logging
â”‚   â””â”€â”€ tests/
â”‚
â”œâ”€â”€ memory-service/        # Multi-tier memory storage
â”‚   â”œâ”€â”€ service/
â”‚   â”‚   â”œâ”€â”€ storage/
â”‚   â”‚   â”‚   â”œâ”€â”€ redis.py        # Session cache
â”‚   â”‚   â”‚   â”œâ”€â”€ vector.py       # Milvus/Chroma
â”‚   â”‚   â”‚   â”œâ”€â”€ postgres.py     # Structured data
â”‚   â”‚   â”‚   â””â”€â”€ s3.py           # Cold storage
â”‚   â”‚   â”œâ”€â”€ embedding.py        # Text embeddings
â”‚   â”‚   â””â”€â”€ tasks.py            # Compaction jobs
â”‚   â””â”€â”€ tests/
â”‚
â”œâ”€â”€ mcp-gateway/           # MCP tool gateway
â”‚   â”œâ”€â”€ service/
â”‚   â”‚   â”œâ”€â”€ catalog.py          # Tool registry
â”‚   â”‚   â”œâ”€â”€ proxy.py            # Runtime proxy
â”‚   â”‚   â”œâ”€â”€ auth.py             # Scoped access
â”‚   â”‚   â””â”€â”€ rate_limit.py       # Throttling
â”‚   â””â”€â”€ tests/
â”‚
â”œâ”€â”€ code-exec/             # Skill executor & sandbox
â”‚   â”œâ”€â”€ service/
â”‚   â”‚   â”œâ”€â”€ executor.py         # Sandboxed execution
â”‚   â”‚   â”œâ”€â”€ skill_registry.py   # Auto-discovery
â”‚   â”‚   â””â”€â”€ skill_parser.py     # Dual-format parsing
â”‚   â”œâ”€â”€ skills/            # Prepackaged skills
â”‚   â”‚   â”œâ”€â”€ text_summarize/
â”‚   â”‚   â”œâ”€â”€ extract_entities/
â”‚   â”‚   â””â”€â”€ prepackaged/
â”‚   â””â”€â”€ tests/
â”‚
â”œâ”€â”€ tools/                 # CLI utilities
â”‚   â””â”€â”€ agentctl/          # Developer CLI
â”‚       â”œâ”€â”€ agentctl/
â”‚       â”‚   â”œâ”€â”€ commands/       # CLI commands
â”‚       â”‚   â”œâ”€â”€ memory/         # Memory management
â”‚       â”‚   â””â”€â”€ templates/      # Code generation
â”‚       â””â”€â”€ tests/
â”‚
â”œâ”€â”€ docs/                  # Documentation
â”‚   â”œâ”€â”€ schema_registry/   # JSON Schemas for artifacts
â”‚   â””â”€â”€ schemas/           # YAML manifest schemas
â”‚
â”œâ”€â”€ examples/              # Example projects
â”‚   â”œâ”€â”€ 01-simple-agent/
â”‚   â”œâ”€â”€ 02-multi-step-workflow/
â”‚   â”œâ”€â”€ 03-custom-skill/
â”‚   â””â”€â”€ 04-mcp-integration/
â”‚
â”œâ”€â”€ tests/                 # Integration tests
â”‚   â””â”€â”€ integration/
â”‚
â”œâ”€â”€ scripts/               # Utility scripts
â”œâ”€â”€ docker-compose.yml     # Full-stack infrastructure
â”œâ”€â”€ pyproject.toml         # Package metadata
â”œâ”€â”€ requirements.txt       # Dependencies
â”œâ”€â”€ CONTRIBUTING.md        # Contribution guidelines
â”œâ”€â”€ CHANGELOG.md           # Version history
â””â”€â”€ LICENSE                # MIT License
```

## ğŸ¢ Production Deployment

### Docker Compose (Development/Testing)

```bash
# Start all services
docker-compose up -d

# Check status
docker-compose ps

# View logs
docker-compose logs -f orchestrator

# Stop services
docker-compose down
```

### Kubernetes (Production)

```bash
# Using Helm charts
helm install agentic-framework ./infra/helm/agentic-framework \
  --set llm.provider=anthropic \
  --set llm.apiKeySecret=anthropic-key \
  --set redis.enabled=true \
  --set postgres.enabled=true \
  --set milvus.enabled=true

# Check deployment
kubectl get pods -n agentic-framework

# Scale orchestrator
kubectl scale deployment orchestrator --replicas=5
```

### Environment Variables

```bash
# LLM Provider (choose one)
ANTHROPIC_API_KEY=sk-ant-...
OPENAI_API_KEY=sk-...
AZURE_OPENAI_KEY=...
AZURE_OPENAI_ENDPOINT=https://...
GEMINI_API_KEY=...

# Infrastructure
REDIS_URL=redis://localhost:6379
POSTGRES_URL=postgresql://user:pass@localhost:5432/agentic
MILVUS_URL=http://localhost:19530
S3_ENDPOINT=http://localhost:9000
S3_ACCESS_KEY=minioadmin
S3_SECRET_KEY=minioadmin

# Services
ORCHESTRATOR_URL=http://localhost:8000
SUBAGENT_MANAGER_URL=http://localhost:8001
MEMORY_SERVICE_URL=http://localhost:8002
MCP_GATEWAY_URL=http://localhost:8003
CODE_EXEC_URL=http://localhost:8004

# Observability
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317
PROMETHEUS_URL=http://localhost:9090
GRAFANA_URL=http://localhost:3000

# Security
JWT_SECRET_KEY=your-secret-key
ENABLE_RBAC=true
REQUIRE_APPROVALS=true
```

### Performance Tuning

```yaml
# orchestrator/config.yaml
performance:
  max_concurrent_workflows: 100
  subagent_pool_size: 50
  connection_pool_size: 20
  cache_ttl: 3600

memory:
  compaction_interval: 300  # seconds
  max_session_size_mb: 100
  vector_batch_size: 1000

timeouts:
  default_step_timeout: 30
  max_workflow_timeout: 3600
  llm_request_timeout: 60
```

## ğŸ¤ Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for detailed guidelines.

### Quick Contribution Guide

1. **Fork** the repository
2. **Create** a feature branch:
   ```bash
   git checkout -b feature/amazing-feature
   ```
3. **Make** your changes:
   - Follow code quality standards (Black, mypy, ruff)
   - Add tests (maintain 90%+ coverage)
   - Update documentation
4. **Test** your changes:
   ```bash
   pytest
   black --check .
   mypy --strict .
   ```
5. **Commit** with conventional commits:
   ```bash
   git commit -m "feat: add amazing feature"
   ```
6. **Push** to your fork:
   ```bash
   git push origin feature/amazing-feature
   ```
7. **Open** a Pull Request

### Development Workflow

```bash
# Create branch
git checkout -b feature/my-feature

# Make changes and test
pytest
black --line-length 100 .
mypy --strict .

# Commit with conventional commits
git commit -m "feat: add new skill registry feature"

# Push and create PR
git push origin feature/my-feature
gh pr create --title "feat: add new skill registry feature"
```

## â“ FAQ

### General Questions

**Q: What makes this different from LangChain or AutoGen?**
A: We focus on production-grade features: typed artifacts with provenance, LLM-agnostic architecture, declarative YAML workflows, enterprise security (RBAC, audit trails), and multi-tier memory management. LangChain/AutoGen are great for prototyping but lack governance features for production.

**Q: Can I use local/open-source LLMs?**
A: Yes! We support Ollama (easiest) and vLLM (fastest) for running models like Llama 3.1, Mistral, and any HuggingFace model locally with zero API costs.

**Q: Is this production-ready?**
A: Yes. The framework includes comprehensive tests (90%+ coverage), observability (OpenTelemetry), security (RBAC, audit trails), and has been designed for enterprise workloads. We recommend starting with pilot projects.

**Q: How does pricing work?**
A: The framework itself is MIT-licensed (free). You pay only for:
- LLM provider API calls (Anthropic/OpenAI/Azure/Gemini) OR
- Infrastructure costs for local LLMs (compute, storage)
- Cloud infrastructure (if deployed on AWS/GCP/Azure)

### Technical Questions

**Q: How do I switch LLM providers?**
A: Use `agentctl llm config --provider <name>` or set environment variables. No code changes needed - all adapters use the same interface.

**Q: What's the difference between Skills and MCP Tools?**
A: **Skills** are deterministic Python functions you write (e.g., data processing, calculations). **MCP Tools** are external services accessed via Model Context Protocol (e.g., GitHub API, file system, databases).

**Q: How does memory compaction work?**
A: The Memory Service automatically summarizes and archives old conversation data based on configurable rules (time-based, token-based, or custom). This prevents context window overflow while preserving important information.

**Q: Can agents call other agents?**
A: Yes! Use the **Hierarchical Delegation** pattern where a lead agent spawns subagents. Each subagent has isolated context and capabilities.

**Q: How do I add a new LLM provider?**
A: Implement the `BaseLLMAdapter` interface in `adapters/llm/`. See existing adapters for examples. Contributions welcome!

**Q: What's the maximum workflow size?**
A: No hard limit. We've tested workflows with 50+ steps. Performance depends on your infrastructure (Redis, Postgres, etc.) and LLM provider rate limits.

### Security Questions

**Q: How are skills sandboxed?**
A: Skills execute in isolated Python processes with restricted imports and filesystem access. You can configure safety flags (`file_system`, `network_access`) to control permissions.

**Q: How is PII handled?**
A: The MCP Gateway includes configurable PII filters. You can also mark skills with `pii_risk` flag to require approval before execution.

**Q: What audit/compliance features exist?**
A: Every artifact includes full provenance (who, what, when, why, inputs, outputs). All actions logged to Postgres for compliance auditing. RBAC controls who can create/execute workflows.

### Deployment Questions

**Q: What are the minimum infrastructure requirements?**
A: For development: Docker Desktop. For production: Kubernetes cluster with 4GB RAM (orchestrator + services) + LLM provider or local GPU for inference.

**Q: Can I run this without Docker?**
A: Yes, but you'll need to manually install and configure Redis, Postgres, and Milvus. See `docker-compose.yml` for service configurations.

**Q: How do I monitor production deployments?**
A: Use the included Prometheus metrics and Grafana dashboards. All services expose `/metrics` endpoints with OpenTelemetry instrumentation.

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

Built with:
- [FastAPI](https://fastapi.tiangolo.com/) - High-performance web framework
- [Pydantic](https://docs.pydantic.dev/) - Data validation
- [anyio](https://anyio.readthedocs.io/) - Async I/O
- [SQLModel](https://sqlmodel.tiangolo.com/) - SQL databases
- [Redis](https://redis.io/) - In-memory cache
- [PostgreSQL](https://www.postgresql.org/) - Relational database
- [Milvus](https://milvus.io/) / [Chroma](https://www.trychroma.com/) - Vector databases
- [MinIO](https://min.io/) - S3-compatible object storage

LLM Providers:
- [Anthropic Claude](https://www.anthropic.com/)
- [OpenAI GPT](https://openai.com/)
- [Azure OpenAI](https://azure.microsoft.com/en-us/products/ai-services/openai-service)
- [Google Gemini](https://ai.google.dev/)
- [Ollama](https://ollama.ai/)
- [vLLM](https://github.com/vllm-project/vllm)

Standards:
- [Model Context Protocol (MCP)](https://modelcontextprotocol.io/)
- [OpenTelemetry](https://opentelemetry.io/)
- [JSON Schema](https://json-schema.org/)

## ğŸ“ Support

### Documentation

- **[CLI Usage Guide](docs/cli-usage.md)** - Interactive CLI tutorial (beginner â†’ advanced)
- **[API Reference](docs/api-reference.md)** - Complete API documentation
- **[Workflow Manifests](docs/manifests.md)** - YAML workflow guide
- **[Skills Development](docs/skills.md)** - Creating custom skills
- **[MCP Integration](docs/mcp.md)** - External tool integration
- **[Examples](examples/)** - Working code examples

### Community & Support

- **Issues**: [GitHub Issues](https://github.com/paragajg/agentic-framework/issues)
- **Discussions**: [GitHub Discussions](https://github.com/paragajg/agentic-framework/discussions)
- **Email**: dev@agentic-framework.org

## ğŸ—ºï¸ Roadmap

See [CHANGELOG.md](CHANGELOG.md) for version history and [GitHub Projects](https://github.com/paragajg/agentic-framework/projects) for upcoming features.

### Upcoming Features (v1.1.0)
- [ ] Web UI for workflow visualization
- [ ] GraphQL API support
- [ ] Streaming responses
- [ ] Advanced routing patterns (conditional, loop)
- [ ] Multi-tenancy support
- [ ] Cost tracking and budget alerts

### Future Releases
- [ ] Distributed execution (Celery/Prefect)
- [ ] Fine-tuned models for specific tasks
- [ ] Browser-based agent playground
- [ ] Mobile SDK (iOS/Android)
- [ ] More MCP servers (Salesforce, Notion, etc.)

---

**Made with â¤ï¸ by the Agentic Framework community**

â­ **Star this repo** if you find it useful!
ğŸ› **Report bugs** via [GitHub Issues](https://github.com/paragajg/agentic-framework/issues)
ğŸ’¡ **Suggest features** via [Discussions](https://github.com/paragajg/agentic-framework/discussions)
